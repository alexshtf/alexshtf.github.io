{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qSWMnjgrTt4h"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQ1Mu7VwgvzoAdMOwE6dyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "589a1198924440fbbefac96232fc8367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfefbe32b7114d5d9fc32a91a19412db",
              "IPY_MODEL_a3705561b1c843e884c094e2c07243f1",
              "IPY_MODEL_939b769418044fd38b22bf060209ed2b"
            ],
            "layout": "IPY_MODEL_9d4738dd1f7b4e4fbf84cacb72168165"
          }
        },
        "dfefbe32b7114d5d9fc32a91a19412db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56347d50a75a4243938d6fedcff8fde3",
            "placeholder": "​",
            "style": "IPY_MODEL_4485a934c6c5442fa999f721c4e877b0",
            "value": "100%"
          }
        },
        "a3705561b1c843e884c094e2c07243f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e241508ef954bc0860d70ab5f1a6bbb",
            "max": 7813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f1d942b06a94097aa04dd63846b4360",
            "value": 7813
          }
        },
        "939b769418044fd38b22bf060209ed2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba62117fd734d1c9cfcd2784bc460bd",
            "placeholder": "​",
            "style": "IPY_MODEL_cfc423747fb942268453e0986c51d721",
            "value": " 7813/7813 [00:00&lt;00:00, 26950.48it/s]"
          }
        },
        "9d4738dd1f7b4e4fbf84cacb72168165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56347d50a75a4243938d6fedcff8fde3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4485a934c6c5442fa999f721c4e877b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e241508ef954bc0860d70ab5f1a6bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1d942b06a94097aa04dd63846b4360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ba62117fd734d1c9cfcd2784bc460bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc423747fb942268453e0986c51d721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexshtf/alexshtf.github.io/blob/master/assets/batch_iter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iGLG34JHgZ4j"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "1wr-2itwtzYU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 1000\n",
        "n_samples = 500000\n",
        "X = torch.randn(n_samples, n_features, device=device)\n",
        "y = torch.randn(n_samples, device=device)"
      ],
      "metadata": {
        "id": "oOnzrj1ogfEo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "def make_network():\n",
        "\treturn nn.Sequential(\n",
        "  \tnn.Linear(n_features, n_features // 2),\n",
        "  \tnn.ReLU(),\n",
        "  \tnn.Linear(n_features // 2, n_features // 8),\n",
        "  \tnn.ReLU(),\n",
        "    nn.Linear(n_features // 8, 1)\n",
        "\t)"
      ],
      "metadata": {
        "id": "B6xq93srhAdj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measure time with DataLoader"
      ],
      "metadata": {
        "id": "oLVXorrvTlDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = make_network().to(device)\n",
        "optim = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "ds = torch.utils.data.TensorDataset(X, y)"
      ],
      "metadata": {
        "id": "jQqQXNjQhwpE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for Xb, yb in torch.utils.data.DataLoader(ds, batch_size=64, shuffle=True):\n",
        "  loss = criterion(net(Xb).squeeze(), yb)\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  optim.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34dEUWYQhyn2",
        "outputId": "3bf7e36f-0842-4686-aa8b-d1c9b4d445ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.3 s, sys: 414 ms, total: 12.7 s\n",
            "Wall time: 13.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for Xb, yb in torch.utils.data.DataLoader(ds, batch_size=64, shuffle=True):\n",
        "\tpass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCk421IZiBIF",
        "outputId": "7b32bc9e-9dbb-4b1a-9be2-0512e95e8bdd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.78 s, sys: 25.5 ms, total: 4.8 s\n",
            "Wall time: 4.86 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measure time with manual iteration"
      ],
      "metadata": {
        "id": "bktVInNvTp_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without shuffling"
      ],
      "metadata": {
        "id": "qSWMnjgrTt4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iter_tensors(*tensors, batch_size):\n",
        "  device = tensors[0].device  # we assume all tensors are on the same device\n",
        "  n = tensors[0].size(0)\n",
        "  idxs = torch.arange(n, device=device).split(batch_size)\n",
        "  for batch_idxs in idxs:\n",
        "    yield tuple((x[batch_idxs, ...] for x in tensors))"
      ],
      "metadata": {
        "id": "yFL7Coh4i3LN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for Xb, yb in iter_tensors(X, y, batch_size=64):\n",
        "\tpass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpqcCwrXTvTW",
        "outputId": "8a672341-f662-4ea7-e118-99f4c8b7c515"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 221 ms, sys: 13.8 ms, total: 235 ms\n",
            "Wall time: 270 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With shuffling"
      ],
      "metadata": {
        "id": "rNzv9LsjUc8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iter_tensors_with_shuffle(*tensors, batch_size, shuffle=False):\n",
        "  device = tensors[0].device  # we assume all tensors are on the same device\n",
        "  n = tensors[0].size(0)\n",
        "  if shuffle:\n",
        "    idxs = torch.arange(n, device=device)\n",
        "  else:\n",
        "    idxs = torch.randperm(n, device=device)\n",
        "  idxs = idxs.split(batch_size)\n",
        "  for batch_idxs in idxs:\n",
        "    yield tuple((x[batch_idxs, ...] for x in tensors))"
      ],
      "metadata": {
        "id": "FqJ5jMSDT5p6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for Xb, yb in iter_tensors_with_shuffle(X, y, batch_size=64, shuffle=True):\n",
        "\tpass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFpF8Lt-Ugw_",
        "outputId": "67100aed-a16f-45e1-8e19-1b13ae7d01d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 213 ms, sys: 0 ns, total: 213 ms\n",
            "Wall time: 212 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With BatchIter"
      ],
      "metadata": {
        "id": "DGonmkW8VpKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchIter:\n",
        "    def __init__(self, *tensors, batch_size, shuffle=True):\n",
        "      \"\"\"\n",
        "      tensors: feature tensors (each with shape: num_samples x *)\n",
        "      batch_size: int\n",
        "      shuffle: bool (default: True) whether to iterate over randomly shuffled samples.\n",
        "      \"\"\"\n",
        "      self.tensors = tensors\n",
        "\n",
        "      device = tensors[0].device\n",
        "      n = tensors[0].size(0)\n",
        "      if shuffle:\n",
        "          idxs = torch.randperm(n, device=device)\n",
        "      else:\n",
        "          idxs = torch.arange(n, device=device)\n",
        "\n",
        "      self.idxs = idxs.split(batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __iter__(self):\n",
        "        tensors = self.tensors\n",
        "        for batch_idxs in self.idxs:\n",
        "            yield tuple((x[batch_idxs, ...] for x in tensors))"
      ],
      "metadata": {
        "id": "iqGkBH6PUkEZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "ZYRUXHzUXnj-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for Xb, yb in tqdm(BatchIter(X, y, batch_size=64, shuffle=True)):\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "589a1198924440fbbefac96232fc8367",
            "dfefbe32b7114d5d9fc32a91a19412db",
            "a3705561b1c843e884c094e2c07243f1",
            "939b769418044fd38b22bf060209ed2b",
            "9d4738dd1f7b4e4fbf84cacb72168165",
            "56347d50a75a4243938d6fedcff8fde3",
            "4485a934c6c5442fa999f721c4e877b0",
            "6e241508ef954bc0860d70ab5f1a6bbb",
            "9f1d942b06a94097aa04dd63846b4360",
            "6ba62117fd734d1c9cfcd2784bc460bd",
            "cfc423747fb942268453e0986c51d721"
          ]
        },
        "id": "nmnoRg8RVrkX",
        "outputId": "ffe7ce66-7c6f-4e34-b498-9a2cc70288c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7813 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "589a1198924440fbbefac96232fc8367"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 309 ms, sys: 28.2 ms, total: 337 ms\n",
            "Wall time: 425 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With grouping"
      ],
      "metadata": {
        "id": "fCnh0F0UZM6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lexsort(*keys, dim=-1):\n",
        "    if len(keys) == 0:\n",
        "        raise ValueError(f\"Must have at least 1 key, but {len(keys)=}.\")\n",
        "\n",
        "    idx = keys[0].argsort(dim=dim, stable=True)\n",
        "    for k in keys[1:]:\n",
        "        idx = idx.gather(dim, k.gather(dim, idx).argsort(dim=dim, stable=True))\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "QZefQd77ZORJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = torch.tensor([5, 3, 5, 3, 5, 5, 3])\n",
        "second = torch.tensor([4, 1, 1, 3, 3, 2, 2])\n",
        "order = lexsort(second, first)\n",
        "print(first[order], second[order])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPA14YwoZO8c",
        "outputId": "f73a393e-5136-4d5a-e9f3-d431667976a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 5, 5, 5, 5]) tensor([1, 2, 3, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def view_as_bytes(x):\n",
        "  element_bytes = x.dtype.itemsize\n",
        "  bytes_tensor = x.view(torch.uint8).view(x.shape + (element_bytes,))\n",
        "  return bytes_tensor.unbind(dim=-1)"
      ],
      "metadata": {
        "id": "vTGCj3ndZRfC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view_as_bytes(4 ** torch.arange(8, dtype=torch.int16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSSHvjXzCIsf",
        "outputId": "0986631b-8c4d-4cc9-804f-cd7352fb05d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  4, 16, 64,  0,  0,  0,  0], dtype=torch.uint8),\n",
              " tensor([ 0,  0,  0,  0,  1,  4, 16, 64], dtype=torch.uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fnv_hash(tensor):\n",
        "    \"\"\"\n",
        "    Computes the FNV hash for each component of a PyTorch tensor of integers.\n",
        "    Args:\n",
        "      tensor: torch.tensor the tensor for which we compute element-wise FNV hash\n",
        "    Returns:\n",
        "      A PyTorch tensor of the same size and dtype as the input tensor, containing the FNV hash for each element.\n",
        "    \"\"\"\n",
        "    # Define the FNV prime and offset basis\n",
        "    FNV_PRIME = torch.tensor(0x01000193, dtype=torch.uint32)\n",
        "    FNV_OFFSET = torch.tensor(0x811c9dc5, dtype=torch.uint32)\n",
        "\n",
        "    # Initialize the hash value with zeros (same size and dtype as tensor)\n",
        "    hash_value = torch.full_like(tensor, FNV_OFFSET)\n",
        "    for byte in view_as_bytes(tensor):\n",
        "        hash_value = torch.bitwise_xor(hash_value * FNV_PRIME, byte)\n",
        "\n",
        "    # No need to reshape, output already has the same size and dtype as input\n",
        "    return hash_value"
      ],
      "metadata": {
        "id": "DQjstztbEB7n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_id = torch.tensor([5, 5, 8, 8, 8, 8, 1, 1])\n",
        "seed = 1\n",
        "order = lexsort(group_id, fnv_hash(group_id + seed))\n",
        "print(group_id[order])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJsgVUDsEbkg",
        "outputId": "1d3f26ac-3720-4900-9068-2d9ebeb9190e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 5, 1, 1, 8, 8, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2\n",
        "order = lexsort(group_id, fnv_hash(group_id + seed))\n",
        "print(group_id[order])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5LwUapPEoYS",
        "outputId": "b0135627-a9b3-417e-8c00-c0bfd5028caf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 8, 8, 8, 8, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def group_idx(group_id):\n",
        "  values, counts = group_id.unique_consecutive(return_counts=True)\n",
        "  idx = torch.cumsum(counts, dim=-1)\n",
        "  return torch.nn.functional.pad(idx, (1, 0))"
      ],
      "metadata": {
        "id": "uYf_z8OQFnge"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_id = torch.tensor([8, 8, 8, 1, 1, 7, 7, 7, 7])\n",
        "indices = group_idx(group_id)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEKvoF2KMEGf",
        "outputId": "c806fb09-ff22-4d59-bbb9-bf6bd320b2b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 3, 5, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_endpoint_indices(group_idx, batch_size):\n",
        "  # pad group_idx to the smallest multiple of batch_size\n",
        "  padding_size = batch_size - (len(group_idx) - batch_size * (len(group_idx) // batch_size))\n",
        "  if padding_size > 0:\n",
        "    padding = group_idx[-1].expand(padding_size)\n",
        "    group_idx = torch.cat((group_idx, padding), dim=-1)\n",
        "\n",
        "  # extract start and end points\n",
        "  start_points = group_idx[0:-1:batch_size]\n",
        "  end_points = group_idx[batch_size::batch_size]\n",
        "\n",
        "  # return them as a list, so we can iterate over them\n",
        "  return start_points.tolist(), end_points.tolist()"
      ],
      "metadata": {
        "id": "JGQnLAf4PZPD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from_idx, to_idx = batch_endpoint_indices(group_idx(group_id), batch_size=2)\n",
        "for start, end in zip(from_idx, to_idx):\n",
        "  print(start, end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IcE2UevMFZs",
        "outputId": "5012006b-b3c0-4a21-855a-7fa43e82c12e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5\n",
            "5 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from_idx, to_idx = batch_endpoint_indices(group_idx(group_id), batch_size=3)\n",
        "for start, end in zip(from_idx, to_idx):\n",
        "  print(start, end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKYxgRYsPaz5",
        "outputId": "b8dd11b3-85b4-41f4-91c4-e18f97e19d29"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GroupBatchIter:\n",
        "  def __init__(self, group_id, *tensors, batch_size=1, shuffle=True, shuffle_seed=42):\n",
        "    self.group_id = group_id\n",
        "    self.tensors = tensors\n",
        "\n",
        "    if shuffle:\n",
        "      self.idxs = lexsort(group_id, fnv_hash(group_id + seed))\n",
        "    else:\n",
        "      self.idxs = torch.arange(len(group_id), device=group_id.device)\n",
        "\n",
        "    group_start_indices = group_idx(group_id[self.idxs])\n",
        "    self.batch_start, self.batch_end = batch_endpoint_indices(group_start_indices, batch_size)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.batch_start)\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    # we create mini-batches containing both group-id, and the additional\n",
        "    # tensors\n",
        "    tensors = (self.group_id,) + self.tensors\n",
        "\n",
        "    # iterate over batch endpoints, and yield tensors\n",
        "    for start, end in zip(self.batch_start, self.batch_end):\n",
        "      batch_idxs = self.idxs[start:end]\n",
        "      if len(batch_idxs) > 0:\n",
        "        yield tuple(x[batch_idxs, ...] for x in tensors)"
      ],
      "metadata": {
        "id": "63lrGcJDfq9q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "group_id = torch.tensor([8, 8, 8, 1, 1, 7, 7, 7, 7])\n",
        "features = torch.arange(len(group_id) * 3).reshape(len(group_id), 3)\n",
        "labels = torch.arange(len(group_id)) % 2\n",
        "\n",
        "print(pd.DataFrame.from_dict({\n",
        "    'group_id': group_id.tolist(),\n",
        "    'features': features.tolist(),\n",
        "    'labels': labels.tolist()\n",
        "}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azWIup68g_7E",
        "outputId": "1529984d-4811-4167-ffa4-ea9f4b1895c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   group_id      features  labels\n",
            "0         8     [0, 1, 2]       0\n",
            "1         8     [3, 4, 5]       1\n",
            "2         8     [6, 7, 8]       0\n",
            "3         1   [9, 10, 11]       1\n",
            "4         1  [12, 13, 14]       0\n",
            "5         7  [15, 16, 17]       1\n",
            "6         7  [18, 19, 20]       0\n",
            "7         7  [21, 22, 23]       1\n",
            "8         7  [24, 25, 26]       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for gb, Xb, yb in GroupBatchIter(group_id, features, labels, batch_size=2, shuffle=True):\n",
        "  print(pd.DataFrame.from_dict({\n",
        "    'group_id': gb.tolist(),\n",
        "    'features': Xb.tolist(),\n",
        "    'labels': yb.tolist()\n",
        "}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLEXqQhXhQPX",
        "outputId": "8080f6e9-5903-43b6-db5c-3c4580993e88"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   group_id      features  labels\n",
            "0         1   [9, 10, 11]       1\n",
            "1         1  [12, 13, 14]       0\n",
            "2         8     [0, 1, 2]       0\n",
            "3         8     [3, 4, 5]       1\n",
            "4         8     [6, 7, 8]       0\n",
            "   group_id      features  labels\n",
            "0         7  [15, 16, 17]       1\n",
            "1         7  [18, 19, 20]       0\n",
            "2         7  [21, 22, 23]       1\n",
            "3         7  [24, 25, 26]       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_groups = n_samples // 8\n",
        "group_id, _ = torch.multinomial(torch.ones(n_groups) / n_groups, n_samples, replacement=True).sort()\n",
        "print(group_id[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YkvcIArhX6d",
        "outputId": "022dddbb-929d-4dea-8d48-9c1a4af31bd9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
            "        6, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for gb, Xb, yb in GroupBatchIter(group_id, X, y, batch_size=64, shuffle=True):\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9miZQ-KGkWZx",
        "outputId": "13feaf35-16ec-47b4-ac86-cea2df07d8e0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 180 ms, sys: 25 ms, total: 205 ms\n",
            "Wall time: 206 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VOYYO0AAko2s"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}